# kudu系统性文档

- 作者：codehackfox@gmail.com
- 时间：2019-04-16 18:39:21
- 状态：pending
- 标签：数据库 大数据存储

[TOC]

> ### 0x01、简介

#### 1.整体架构
- kudu是一个分布式列式存储工具
- 整体架构图
    - ![kudu-arch](https://kudu.apache.org/docs/images/kudu-architecture-2.png)
- 适用场景
    - 在流式的数据中近乎实时的查询性能
    - 具有广泛变化的访问模式的时序应用程序
    - 需要根据已知存储的数据来预测建模
    - 将Kudu中的数据与遗留系统相结合

#### 2.设计模式
- Kudu的表是类似于传统关系型数据库的表类型。 表的设计对于kudu的使用性能是至关重要的。然而对于表结构的设计没有一个统一的方案，需要根据具体的数据类型来进行应用。
- 最主要关心的是：列的设计、主键的设计和分区设计

> ##### 最优Schema实践

- Data would be distributed in such a way that reads and writes are spread evenly across tablet servers. This is impacted by partitioning.
- Tablets would grow at an even, predictable rate and load across tablets would remain steady over time. This is most impacted by partitioning.
- Scans would read the minimum amount of data necessary to fulfill a query. This is impacted mostly by primary key design, but partitioning also plays a role via partition pruning.
- The perfect schema depends on the characteristics of your data, what you need to do with it, and the topology of your cluster. Schema design is the single most important thing within your control to maximize the performance of your Kudu cluster.

> ##### 列设计

- Kudu 表由一个列或多个列组成，每个列都有一个定义的类型。不属于主键的列可能为空。支持的列类型包括：
    * boolean
    * 8-bit signed integer
    * 16-bit signed integer
    * 32-bit signed integer
    * 64-bit signed integer
    * unixtime_micros (从 UNIX 时代起，64 位微秒)
    * single-precision (32-bit) IEEE-754 floating-point number ( 单精度，32位，IEEE-754 浮点数 )
    * double-precision (64-bit) IEEE-754 floating-point number ( 双精度，64位，IEEE-754 浮点数 )
    * UTF-8 encoded string (up to 64KB uncompressed) ( UTF-8 编码字符串（高达 64KB 未压缩） )
    * binary (up to 64KB uncompressed) ( 二进制（高达 64KB 未压缩） )
- Kudu 利用强类型的列和柱状磁盘存储格式来提供高效的编码和序列化。为了充分利用这些功能，列应该被指定为适当的类型，而不是使用字符串或二进制列来模拟'schemaless'表，否则可能会进行结狗化。除了编码之外，Kudu 允许按照每列进行压缩。
- 没有版本或者时间戳列
    - 不像Hbase，kudu没有一个隐藏的版本或者时间戳列。如果确实需要，必须进行显示的声明。

> ##### Decimal类型

- The decimal type is a numeric data type with fixed scale and precision suitable for financial and other arithmetic calculations where the imprecise representation and rounding behavior of float and double make those types impractical. The decimal type is also useful for integers larger than int64 and cases with fractional values in a primary key.
    * Decimal values with precision of 9 or less are stored in 4 bytes.
    * Decimal values with precision of 10 through 18 are stored in 8 bytes.
    * Decimal values with precision greater than 18 are stored in 16 bytes.

> ##### 列编码

- kudu的每一个列都可以进行单独设计编码类型
- 表的编码类型

| 列类型 | 编码方式  | 默认 |
| --- | --- | --- |
| int8, int16, int32 | plain, bitshuffle, run length | bitshuffle |
| int64, unixtime_micros | plain, bitshuffle, run length | bitshuffle |
| float, double, decimal | plain, bitshuffle | bitshuffle |
| bool | plain, run length | run length |
| string, binary | plain, prefix, dictionary | dictionary |

- Plain编码
    * Data is stored in its natural format. For example, int32 values are stored as fixed-size 32-bit little-endian integers.

- Bitshuffle编码
    * A block of values is rearranged to store the most significant bit of every value, followed by the second most significant bit of every value, and so on. Finally, the result is LZ4 compressed. Bitshuffle encoding is a good choice for columns that have many repeated values, or values that change by small amounts when sorted by primary key. The bitshuffle project has a good overview of performance and use cases.

- Run Length Encoding
    * Runs (consecutive repeated values) are compressed in a column by storing only the value and the count. Run length encoding is effective for columns with many consecutive repeated values when sorted by primary key.

- Dictionary Encoding
    * A dictionary of unique values is built, and each column value is encoded as its corresponding index in the dictionary. Dictionary encoding is effective for columns with low cardinality. If the column values of a given row set are unable to be compressed because the number of unique values is too high, Kudu will transparently fall back to plain encoding for that row set. This is evaluated during flush.

- Prefix Encoding
    * Common prefixes are compressed in consecutive column values. Prefix encoding can be effective for values that share common prefixes, or the first column of the primary key, since rows are sorted by primary key within tablets.

> ##### 列压缩

- Kudu allows per-column compression using the `LZ4`, `Snappy`, or `zlib` compression codecs
- By default, columns are stored uncompressed. Consider using compression if reducing storage space is more important than raw scan performance.
- Every data set will compress differently, but in general LZ4 is the most performant codec, while zlib will compress to the smallest data sizes. Bitshuffle-encoded columns are automatically compressed using LZ4, so it is not recommended to apply additional compression on top of this encoding.

> ##### 主键设计

- Every Kudu table must declare a primary key comprised of one or more columns. Like an RDBMS primary key, the Kudu primary key enforces a uniqueness constraint. Attempting to insert a row with the same primary key values as an existing row will result in a duplicate key error.
    * Primary key columns must be non-nullable, and may not be a boolean, float or double type.
    * Once set during table creation, the set of columns in the primary key may not be altered.
    * Unlike an RDBMS, Kudu does not provide an auto-incrementing column feature, so the application must always provide the full primary key during insert.
    * Row delete and update operations must also specify the full primary key of the row to be changed. Kudu does not natively support range deletes or updates.
    * The primary key values of a column may not be updated after the row is inserted. However, the row may be deleted and re-inserted with the updated value.

> ##### 主键索引

- As with many traditional relational databases, Kudu’s primary key is in a clustered index. All rows within a tablet are sorted by its primary key.
- When scanning Kudu rows, use equality or range predicates on primary key columns to efficiently find the rows.

> ##### 分区方式

- hash
- range
- hash & range

#### 3.通用操作

```python
import kudu
from kudu.client import Partitioning
from datetime import datetime

# Connect to Kudu master server
client = kudu.connect(host='kudu.master', port=7051)

# Define a schema for a new table
builder = kudu.schema_builder()
builder.add_column('key').type(kudu.int64).nullable(False).primary_key()
builder.add_column('ts_val', type_=kudu.unixtime_micros, nullable=False, compression='lz4')
schema = builder.build()

# Define hash partitioning schema
partitioning = Partitioning().add_hash_partitions(column_names=['key'],
num_buckets=3)

# define range partition schema
partitioning2 = Partitioning().builder.set_primary_keys(['user_id', 'crawler_time', 'year'])

# Create new table
client.create_table('python-example', schema, partitioning)

# Open a table
table = client.table('python-example')

# Create a new session so that we can apply write operations
session = client.new_session()

# Insert a row
op = table.new_insert({'key': 1, 'ts_val': datetime.utcnow()})
session.apply(op)

# Upsert a row
op = table.new_upsert({'key': 2, 'ts_val': "2016-01-01T00:00:00.000000"})
session.apply(op)

# Updating a row
op = table.new_update({'key': 1, 'ts_val': ("2017-01-01", "%Y-%m-%d")})
session.apply(op)

# Delete a row
op = table.new_delete({'key': 2})
session.apply(op)

# Flush write operations, if failures occur, capture print them.
try:
    session.flush()
except kudu.KuduBadStatus as e:
    print(session.get_pending_errors())

# Create a scanner and add a predicate
scanner = table.scanner()
scanner.add_predicate(table['ts_val'] == datetime(2017, 1, 1))

# Open Scanner and read all tuples
# Note: This doesn't scale for large scans
result = scanner.open().read_all_tuples()
```

#### 4.已知限制

> ##### 结构设计限制

- 主键
    * 当表创建后主键不可修改，除非重建在设置
    * Double、float、bool类型不允许设置为主键
    * 主键字段必须设置为第一个
    * 主键字段值不允许被更新
    * Auto-generated primary keys are not supported.
- Cells
    * No individual cell may be larger than 64KB before encoding or compression. The cells making up a composite key are limited to a total of 16KB afterthe internal composite-key encoding done by Kudu.Inserting rows not conforming to these limitations will result in errors being returned to the client.
- Columns
    * By default, Kudu will not permit the creation of tables with more than 300 columns. We recommend schema designs that use fewer columns for best performance.
    * CHAR, VARCHAR, DATE, and complex types such as ARRAY are not supported.
    * Type and nullability of existing columns cannot be changed by altering the table.
    * Dropping a column does not immediately reclaim space. Compaction must run first.
    * The precision and scale of DECIMAL columns cannot be changed by altering the table.
- Rows
    * Kudu was primarily designed for analytic use cases. Although individual cells may be up to 64KB, and Kudu supports up to 300 columns, it isrecommended that no single row be largerthan a few hundred KB. You are likely to encounter issues if a single row contains multiple kilobytes of data.
- Tables
    * Tables must have an odd number of replicas, with a maximum of 7.
    * Replication factor (set at table creation time) cannot be changed.
    * There is no way to run compaction manually, but dropping a table will reclaim the space immediately.
- Other Usage Limitations
    * Secondary indexes are not supported.
    * Multi-row transactions are not supported.
    * Relational features, such as foreign keys, are not supported.
    * Identifiers such as column and table names are restricted to be valid UTF-8 strings. Additionally, a maximum length of 256 characters is enforced.

> ##### 分区限制

- Tables must be manually pre-split into tablets using simple or compound primary keys. Automatic splitting is not yet possible. Kudu does not allow you to change how a table is partitioned after creation, with the exception of adding or dropping range partitions.
- Data in existing tables cannot currently be automatically repartitioned. As a workaround, create a new table with
the new partitioning and insert the contents of the old table.
- Tablets that lose a majority of replicas (such as 1 left out of 3) require manual intervention to be repaired.

> ##### Scaling Recommendations and Limitations

- Recommended maximum number of tablet servers is 100.
- Recommended maximum number of masters is 3.
- Recommended maximum amount ofstored data, post-replication and post-compression, per tabletserver is 8TB.
- Maximum number oftablets pertable for each tabletserveris 60, post-replication (assuming the defaultreplication
factor of 3), at table-creation time.

> ##### Server Management Limitations

- Production deployments should configure a least 4GB of memory for tablet servers, and ideally more than 16GB
when approaching the data and tablet scale limits.
- Write ahead logs (WALs) can only be stored on one disk.
- Data directories cannot be removed. You must reformat the data directories to remove them.
- Tablet servers cannot be gracefully decommissioned.
- Tablet servers cannot change their address or port.
- Kudu has a hard requirement on having an up-to-date NTP. Kudu masters and tablet servers will crash when out of sync.
- Kudu releases have only been tested with NTP. Other time synchronization providers such as Chrony may not work.

> ##### Cluster Management Limitations

- Multi-data-center/multi-availability-zone configurations require at least 3 locations to maintain full Kudu service
availability when one of those locations becomes unavailable.
- Recommended maximum point-to-point latency within a Kudu cluster is 20 milliseconds
- Recommended minimum point-to-point bandwidth within a Kudu cluster is 10 Gbps.
- Rolling restart is not supported.
- All masters must be started at the same time when the cluster is started for the very first time.

> ##### Replication and Backup Limitations

- Kudu does not currently include any built-in features for backup and restore. Users are encouraged to use tools
such as Spark or Impala to export or import tables as necessary.

> ##### Impala Integration Limitations

- When creating a Kudu table, the CREATE TABLE statement must include the primary key columns before other
columns, in primary key order.
- Impala cannot update values in primary key columns.
- Impala cannot create Kudu tables with VARCHAR or nested-typed columns.
- Kudu tables with a name containing upper case or non-ASCII characters must be assigned an alternate name when
used as an external table in Impala.
- Kudu tables with a column name containing upper case or non-ASCII characters cannot be used as an external
table in Impala. Columns can be renamed in Kudu to work around this issue.
- != and LIKE predicates are not pushed to Kudu, and instead will be evaluated by the Impala scan node. This may
decrease performance relative to other types of predicates.
- Updates, inserts, and deletes using Impala are non-transactional. If a query fails part of the way through, its partial
effects will not be rolled back.
- The maximum parallelism of a single query is limited to the number of tablets in a table. For good analytic performance, aim for 10 or more tablets per host or use large tables.
- Impala Keywords Not Supported for Creating Kudu Tables
    * PARTITIONED
    * LOCATION
    * ROWFORMAT

> ##### Security Limitations

- Data encryption at rest is not directly built into Kudu. Encryption of Kudu data at rest can be achieved through the use of local block device encryption software such as dmcrypt.
- Authorization is only available at a system-wide, coarse-grained level. Table-level, column-level, and row-level authorization features are not available.
- Kudu does not support configuring a custom service principal for Kudu processes. The principal must follow the pattern kudu/<HOST>@<DEFAULT.REALM>.
- Kudu integration with Apache Flume does not support writing to Kudu clusters that require authentication.
- Server certificates generated by Kudu IPKI are incompatible with bouncycastle version 1.52 and earlier.


#### 5.配置选项
- ##### 基本配置
    - `--flagfile=<file>`
- ##### 路径配置
    - `--fs_wal_dir`
    - `--fs_metadata_dir`
    - `--fs_wal_dir`
    - `--fs_data_dirs`
    - Each directory specified by a configuration flag on a given machine should be used by at most one Kudu process. If multiple Kudu processes on the same machine are configured to use the same directory, Kudu may refuse to start up.

- ##### master配置
    -  kudu-master --help
    - `--master_addresses`
        * Default: localhost
        * Comma-separated list of all the RPC addresses for Master consensus-configuration. If not specified, assumes a standalone Master.
    - `--fs_data_dirs`
    - `--fs_metadata_dir`
    - `--fs_wal_dir`
    - `--log_dir`
- ##### tablet配置
    - $ kudu-tserver --help
    - `--fs_data_dirs`
    - `--fs_metadata_dir`
    - `--fs_wal_dir`
    - `--log_dir`
    - `--tserver_master_addrs`
    - `--block_cache_capacity_mb`
    - `--memory_limit_hard_bytes`



#### 6.性能统计


> ### 0x02、数据流程

#### 1.分布式架构


#### 2.索引设计


#### 3.存储设计
